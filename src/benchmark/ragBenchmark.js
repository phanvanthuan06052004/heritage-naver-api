/**
 * RAG Benchmark Service
 * X·ª≠ l√Ω benchmark pipeline: retrieve ‚Üí generate ‚Üí evaluate
 */

import { ChromaClient } from 'chromadb'
import { env } from '../config/environment.js'
import { v4 as uuidv4 } from 'uuid'
import { evaluateAnswer } from './metrics.js'

// Kh·ªüi t·∫°o ChromaDB client
const chromaClient = new ChromaClient({ path: env.CHROMA_URL })

/**
 * Retrieve context t·ª´ Chroma vector database
 * 
 * @param {string} question - C√¢u h·ªèi
 * @param {string} collectionName - T√™n collection
 * @param {number} topK - S·ªë l∆∞·ª£ng documents c·∫ßn l·∫•y
 * @returns {Promise<Object>} { context, sources, embeddings }
 */
export const retrieveContext = async (question, collectionName = 'heritage_documents', topK = 5) => {
  try {
    console.log(`   üîç Retrieving context for: "${question.substring(0, 50)}..."`)

    // 1. T·∫°o embedding cho c√¢u h·ªèi
    const questionEmbedding = await generateEmbedding(question)

    if (!questionEmbedding || questionEmbedding.length === 0) {
      console.log('   ‚ö†Ô∏è  No embedding generated, using empty context')
      return {
        context: '',
        sources: [],
        questionEmbedding: null
      }
    }

    // 2. Query Chroma ƒë·ªÉ l·∫•y documents li√™n quan
    try {
      const collection = await chromaClient.getCollection({ name: collectionName })
      
      const results = await collection.query({
        queryEmbeddings: [questionEmbedding],
        nResults: topK,
        include: ['documents', 'metadatas', 'distances']
      })

      const documents = results.documents?.[0] || []
      const metadatas = results.metadatas?.[0] || []
      const distances = results.distances?.[0] || []

      if (documents.length === 0) {
        console.log('   ‚ö†Ô∏è  No documents found in collection')
        return {
          context: '',
          sources: [],
          questionEmbedding
        }
      }

      // 3. Build context t·ª´ documents
      const context = documents
        .map((doc, index) => `[Document ${index + 1}] ${doc}`)
        .join('\n\n')

      const sources = documents.map((doc, index) => ({
        content: doc,
        metadata: metadatas[index] || {},
        distance: distances[index] || 0,
        relevanceScore: 1 - (distances[index] || 0) // Convert distance to similarity
      }))

      console.log(`   ‚úÖ Retrieved ${documents.length} documents`)

      return {
        context,
        sources,
        questionEmbedding
      }
    } catch (collectionError) {
      // Collection kh√¥ng t·ªìn t·∫°i ho·∫∑c l·ªói kh√°c
      if (collectionError.message?.includes('not found') || collectionError.message?.includes('does not exist')) {
        console.log(`   ‚ö†Ô∏è  Collection "${collectionName}" not found`)
      } else {
        console.error('   ‚ùå Error querying collection:', collectionError.message)
      }
      
      return {
        context: '',
        sources: [],
        questionEmbedding
      }
    }
  } catch (error) {
    console.error('   ‚ùå Error in retrieveContext:', error)
    return {
      context: '',
      sources: [],
      questionEmbedding: null
    }
  }
}

/**
 * Generate answer s·ª≠ d·ª•ng Naver Chat API
 * 
 * @param {string} question - C√¢u h·ªèi
 * @param {string} context - Context t·ª´ retrieved documents
 * @param {boolean} useMock - S·ª≠ d·ª•ng mock answer (khi ch∆∞a c√≥ API key)
 * @returns {Promise<Object>} { answer, embedding }
 */
export const generateAnswer = async (question, context, useMock = false) => {
  try {
    console.log('   ü§ñ Generating answer...')

    // Mock mode - ƒë·ªÉ test khi ch∆∞a c√≥ Naver API key
    if (useMock || !env.NAVER_API_KEY || env.NAVER_API_KEY.includes('your_')) {
      console.log('   ‚ö†Ô∏è  Using mock mode (no API key)')
      return await generateMockAnswer(question, context)
    }

    // G·ªçi Naver Chat API
    const systemPrompt = `You are an AI assistant specializing in Vietnamese cultural heritage.
Please answer the question based on the information provided in the context.
If the information is not sufficient to answer, state that clearly.
Provide accurate, concise, and easy-to-understand answers in English.`

    const userPrompt = context
      ? `Context:\n${context}\n\nQuestion: ${question}\n\nAnswer:`
      : `Question: ${question}\n\nAnswer:`

    const response = await fetch(env.NAVER_CHAT_API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${env.NAVER_API_KEY}`,
        'X-NCP-CLOVASTUDIO-REQUEST-ID': uuidv4()
      },
      body: JSON.stringify({
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        topP: 0.8,
        topK: 0,
        maxTokens: 500,
        temperature: 0.3, // Lower temperature cho c√¢u tr·∫£ l·ªùi ch√≠nh x√°c h∆°n
        repeatPenalty: 5.0,
        stopBefore: [],
        includeAiFilters: true
      })
    })

    if (!response.ok) {
      const errorData = await response.text()
      throw new Error(`Naver Chat API error: ${response.status} - ${errorData}`)
    }

    const data = await response.json()
    const answer = data.result?.message?.content || data.content || 'Kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi'

    console.log('   ‚úÖ Answer generated')

    // T·∫°o embedding cho answer
    const answerEmbedding = await generateEmbedding(answer)

    return {
      answer,
      embedding: answerEmbedding
    }
  } catch (error) {
    console.error('   ‚ùå Error generating answer:', error.message)
    
    // Fallback to mock n·∫øu API call failed
    return await generateMockAnswer(question, context)
  }
}

/**
 * Generate mock answer (d√πng khi test m√† ch∆∞a c√≥ API key)
 */
const generateMockAnswer = async (question, context) => {
  // Extract key information t·ª´ context ƒë·ªÉ t·∫°o mock answer
  if (context && context.length > 0) {
    // L·∫•y c√¢u ƒë·∫ßu ti√™n t·ª´ context
    const firstSentence = context.split(/[.!?]/)[0] + '.'
    return {
      answer: `Based on the available information: ${firstSentence}`,
      embedding: null
    }
  }

  return {
    answer: `Sorry, I don't have enough information to answer the question "${question}".`,
    embedding: null
  }
}

/**
 * Generate embedding cho text
 */
const generateEmbedding = async (text) => {
  try {
    // Ki·ªÉm tra API key
    if (!env.NAVER_API_KEY || env.NAVER_API_KEY.includes('your_')) {
      return null // Mock mode
    }

    const response = await fetch(env.NAVER_EMBEDDING_API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${env.NAVER_API_KEY}`,
        'X-NCP-CLOVASTUDIO-REQUEST-ID': uuidv4()
      },
      body: JSON.stringify({ text })
    })

    if (!response.ok) {
      return null
    }

    const data = await response.json()
    return data.result?.embedding || data.embedding || null
  } catch (error) {
    return null
  }
}

/**
 * Benchmark m·ªôt c√¢u h·ªèi ƒë∆°n l·∫ª
 * 
 * @param {Object} testCase - { question, ground_truth, related_docs }
 * @param {Object} options - { collectionName, topK, useMock }
 * @returns {Promise<Object>} K·∫øt qu·∫£ benchmark
 */
export const benchmarkSingleQuestion = async (testCase, options = {}) => {
  const {
    collectionName = 'heritage_documents',
    topK = 5,
    useMock = false
  } = options

  const startTime = Date.now()

  try {
    console.log(`\nüìù Question ${testCase.id}: ${testCase.question}`)

    // 1. Retrieve context
    const retrievalResult = await retrieveContext(testCase.question, collectionName, topK)

    // 2. Generate answer
    const generationResult = await generateAnswer(testCase.question, retrievalResult.context, useMock)

    // 3. Generate embedding cho ground truth (n·∫øu c√≥ API)
    let groundTruthEmbedding = null
    if (!useMock && retrievalResult.questionEmbedding) {
      groundTruthEmbedding = await generateEmbedding(testCase.ground_truth)
    }

    // 4. Evaluate metrics
    console.log('   üìä Evaluating metrics...')
    const metrics = evaluateAnswer(
      generationResult.answer,
      testCase.ground_truth,
      generationResult.embedding,
      groundTruthEmbedding
    )

    const executionTime = Date.now() - startTime

    console.log(`   ‚è±Ô∏è  Execution time: ${executionTime}ms`)
    console.log(`   üìà BLEU: ${metrics.bleu}, ROUGE-L F1: ${metrics.rouge_l_f1}, Cosine: ${metrics.cosine_tfidf}`)

    return {
      id: testCase.id,
      question: testCase.question,
      ground_truth: testCase.ground_truth,
      generated_answer: generationResult.answer,
      context_used: retrievalResult.context,
      sources: retrievalResult.sources,
      metrics: metrics,
      execution_time_ms: executionTime,
      timestamp: new Date().toISOString()
    }
  } catch (error) {
    console.error(`   ‚ùå Error benchmarking question ${testCase.id}:`, error.message)
    
    return {
      id: testCase.id,
      question: testCase.question,
      ground_truth: testCase.ground_truth,
      generated_answer: 'ERROR',
      error: error.message,
      metrics: {
        bleu: 0,
        rouge_l_f1: 0,
        cosine_tfidf: 0
      },
      execution_time_ms: Date.now() - startTime,
      timestamp: new Date().toISOString()
    }
  }
}

/**
 * Benchmark to√†n b·ªô dataset
 * 
 * @param {Array<Object>} testCases - M·∫£ng c√°c test cases
 * @param {Object} options - Options
 * @returns {Promise<Array<Object>>} M·∫£ng k·∫øt qu·∫£
 */
export const benchmarkDataset = async (testCases, options = {}) => {
  console.log(`\nüöÄ Starting benchmark for ${testCases.length} questions...\n`)
  console.log('='.repeat(70))

  const results = []

  for (const testCase of testCases) {
    const result = await benchmarkSingleQuestion(testCase, options)
    results.push(result)

    // Delay nh·ªè gi·ªØa c√°c requests ƒë·ªÉ tr√°nh rate limit
    await new Promise(resolve => setTimeout(resolve, 500))
  }

  console.log('\n' + '='.repeat(70))
  console.log('‚úÖ Benchmark completed!\n')

  return results
}

/**
 * Ki·ªÉm tra xem collection c√≥ t·ªìn t·∫°i v√† c√≥ data kh√¥ng
 */
export const checkCollectionStatus = async (collectionName = 'heritage_documents') => {
  try {
    const collection = await chromaClient.getCollection({ name: collectionName })
    const count = await collection.count()

    return {
      exists: true,
      count: count,
      name: collectionName
    }
  } catch (error) {
    return {
      exists: false,
      count: 0,
      name: collectionName,
      error: error.message
    }
  }
}
